{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note to import from .py files, must follow structure\n",
    "# from <.py filename excluding '.py'> import <class name>\n",
    "# Optionslam creds: aspringfastlaner Options2018\n",
    "\n",
    "# Importing necessary models\n",
    "import smtplib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas.stats.moments as st\n",
    "from pandas import ExcelWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as ticker\n",
    "from lxml import html\n",
    "import requests\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import csv\n",
    "import sched, time\n",
    "import pandas_datareader as datareader\n",
    "from pandas_datareader.data import Options\n",
    "from py_vollib.black_scholes_merton.implied_volatility import *\n",
    "import dash\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skewnorm as skn\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for pulling implied volatility from option slam for single ticker\n",
    "'''\n",
    "\n",
    "def optionslam_scrape(ticker):\n",
    "    site = 'https://www.optionslam.com/earnings/stocks/' + ticker\n",
    "    res = requests.get(site)\n",
    "    soup = bs(requests.get(site).text, \"lxml\")\n",
    "    soup = soup.prettify()\n",
    "    earnings_dict = {'Ticker': ticker}\n",
    "    \n",
    "    # Check if there's weekly options\n",
    "    curr7_implied = \"Current 7 Day Implied Movement:\"\n",
    "    implied_move_weekly = \"Implied Move Weekly:\"\n",
    "    nextearnings = \"Next Earnings Date:\"\n",
    "    if curr7_implied not in soup:\n",
    "        return 'No Weeklies'\n",
    "    \n",
    "    # Parsing if weekly options exist\n",
    "    # Next earnings date and before or after\n",
    "    earnings_start_string = \"Next Earnings Date:\"\n",
    "    earnings_end_string = '</font>'\n",
    "    raw_earnings_string = (soup.split(earnings_start_string))[1].split(earnings_end_string)[0].replace('\\n','').strip()\n",
    "    \n",
    "    try:\n",
    "        earnings_date = str((raw_earnings_string.split('<b>'))[1].split('<font size=\"-1\">')).split(\"'\")[1].strip()\n",
    "    except:\n",
    "        return 'Error Parsing'\n",
    "    \n",
    "    earnings_time = str(raw_earnings_string[-2:].strip()).strip()\n",
    "    \n",
    "    earnings_dict['Date'] = earnings_date\n",
    "    earnings_dict['Earnings Time'] = earnings_time\n",
    "    \n",
    "    # Parsing 7 day implied move if weekly option exists\n",
    "    ending_string = '<font size=\"-2\">'\n",
    "    curr_7 = (soup.split(curr7_implied))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    earnings_dict['Current 7 Day Implied'] = curr_7\n",
    "    \n",
    "    # Parsing Weekly Implied move if weekly option exists\n",
    "    if implied_move_weekly in soup:\n",
    "        weekly_implied = (soup.split(implied_move_weekly))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    else:\n",
    "        weekly_implied = ''\n",
    "    earnings_dict[\"Implied Move Weekly\"] = weekly_implied\n",
    "    \n",
    "    return earnings_dict\n",
    "\n",
    "\n",
    "def generate_table(dataframe):\n",
    "    return html.Table(\n",
    "        # Header\n",
    "        [html.Tr([html.Th(col) for col in dataframe.columns])] +\n",
    "\n",
    "        # Body\n",
    "        [html.Tr([\n",
    "            html.Td(dataframe.iloc[i][col]) for col in dataframe.columns\n",
    "        ]) for i in range(len(dataframe))]\n",
    "    )\n",
    "\n",
    "\n",
    "# Looping through the soup lxml text table format\n",
    "# and splitting each row as a individual string\n",
    "# and parsing string to retrieve the date,\n",
    "# open, and close information.\n",
    "\n",
    "def yahoo_table_parse(raw_html_table):\n",
    "    tickers = []\n",
    "    call_times = []\n",
    "    implied_7_day = []\n",
    "    implied_weekly = []\n",
    "    eps = []\n",
    "    i = 1\n",
    "    end_row = 10\n",
    "    for row in raw_html_table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        row_items = individual_row[0].split('</span>')[:3]\n",
    "\n",
    "        if i == 1:\n",
    "            i += 1\n",
    "            continue\n",
    "        tick = row_items[0].split('data-symbol=\"')[1].split('\"')[0]\n",
    "        os_check = optionslam_scrape(tick)\n",
    "\n",
    "        if type(os_check) == str:\n",
    "            continue\n",
    "        else:\n",
    "            tickers.append(tick)\n",
    "            call_times.append(row_items[0].split('data-symbol=\"')[1].split('\"')[-1].replace('>',''))\n",
    "            eps.append(row_items[1].split('</td>')[1].split('>')[1])\n",
    "            implied_7_day.append(os_check['Current 7 Day Implied'].replace('%',''))\n",
    "            implied_weekly.append(os_check['Implied Move Weekly'].replace('%',''))\n",
    "\n",
    "\n",
    "    return pd.DataFrame({'Tickers': tickers, 'Call Times': call_times, 'EPS': eps,\n",
    "                         'Current 7 Day Implied': implied_7_day,\n",
    "                         'Implied Move Weekly': implied_weekly})\n",
    "\n",
    "\n",
    "def yahoo_earnings(date):\n",
    "    # Yahoo Earnings Calendar Check\n",
    "\n",
    "    today = date.strftime('%Y-%m-%d')\n",
    "    tables = []\n",
    "    for i in range(6):\n",
    "        yahoo_url = 'https://finance.yahoo.com/calendar/earnings?day=' + today + '&offset={}&size=100'.format(int(i*100))\n",
    "        res = requests.get(yahoo_url)\n",
    "        soup = bs(requests.get(yahoo_url).text, \"lxml\")\n",
    "\n",
    "        try:\n",
    "            table = soup.find_all('table')[0]\n",
    "            tables.append(yahoo_table_parse(table))\n",
    "        except:\n",
    "            print('No Table')\n",
    "\n",
    "    return pd.concat(tables,axis = 0, ignore_index = True)\n",
    "\n",
    "\n",
    "def close_data(ticker_lst, start_date = dt.datetime(2018, 2, 20)):\n",
    "    # Define which online source one should use\n",
    "    data_source = 'yahoo'\n",
    "\n",
    "    end = dt.datetime.today()\n",
    "\n",
    "    # User pandas_reader.data.DataReader to load the desired data. As simple as that.\n",
    "    panel_data = datareader.DataReader(ticker_lst, data_source, start_date, end)\n",
    "\n",
    "    # Getting just the adjusted closing prices. This will return a Pandas DataFrame\n",
    "    # The index in this DataFrame is the major index of the panel_data.\n",
    "    return panel_data.ix['Close']\n",
    "\n",
    "\n",
    "# Function for calculating standard dev and price moves in terms of standard dev\n",
    "# DF[[Adj Close]] Rolling Period --> DF[['Daily Vol','Daily Price Vol','Price Dev','Annual Vol']]\n",
    "def price_devs(ticker, lookbackwindow, rollingperiod):\n",
    "    # Define which online source one should use\n",
    "    data_source = 'yahoo'\n",
    "    \n",
    "    end = dt.datetime.today()\n",
    "    start_date = end - dt.timedelta(days = lookbackwindow)\n",
    "    \n",
    "    # User pandas_reader.data.DataReader to load the desired data. As simple as that.\n",
    "    df = datareader.DataReader([ticker], data_source, start_date, end).sort_index()\n",
    "\n",
    "    # Getting just the adjusted closing prices. This will return a Pandas DataFrame\n",
    "    # The index in this DataFrame is the major index of the panel_data.\n",
    "    df = df.ix['Close'].sort_index()\n",
    "    \n",
    "    df.columns = ['prices']\n",
    "    df['prices_delta'] = df.prices - df.prices.shift(1)\n",
    "    df['log_returns'] = np.log(df.prices) - np.log(df.prices.shift(1))\n",
    "    df['daily_vol'] = st.rolling_std(df.log_returns, rollingperiod, ddof = 1)\n",
    "    df['daily_vol_dollar'] = df.daily_vol*df.prices\n",
    "    df['price_dev'] = df.prices_delta/df.daily_vol_dollar.shift(1)\n",
    "    df['annual_vol'] = df.daily_vol*np.sqrt(252)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup app\n",
    "# server = flask.Flask(__name__)\n",
    "# server.secret_key = os.environ.get('secret_key', 'secret')\n",
    "# app = dash.Dash(__name__, server=server, url_base_pathname='/dash/gallery/volatility-surface', csrf_protect=False)\n",
    "app = dash.Dash()\n",
    "\n",
    "external_css = [\"https://fonts.googleapis.com/css?family=Overpass:300,300i\",\n",
    "                \"https://cdn.rawgit.com/plotly/dash-app-stylesheets/dab6f937fd5548cebf4c6dc7e93a10ac438f5efb/dash-technical-charting.css\"]\n",
    "\n",
    "for css in external_css:\n",
    "    app.css.append_css({\"external_url\": css})\n",
    "\n",
    "if 'DYNO' in os.environ:\n",
    "    app.scripts.append_script({\n",
    "        'external_url': 'https://cdn.rawgit.com/chriddyp/ca0d8f02a1659981a0ea7f013a378bbd/raw/e79f3f789517deec58f41251f7dbb6bee72c44ab/plotly_ga.js'\n",
    "    })\n",
    "\n",
    "\n",
    "# Plot Fields\n",
    "returncolumns = ['price_dev','log_returns']\n",
    "plotfields = [dict(label=str(x), value=str(x)) for x in returncolumns]\n",
    "\n",
    "# Current data table for graphing\n",
    "# curr_data = np.round(datacollect.curr_table.tail(),2)\n",
    "# curr_data['Date'] = datacollect.curr_table.tail().index\n",
    "# curr_data = curr_data.iloc[:,::-1]\n",
    "\n",
    "#curr_data = yahoo_earnings()\n",
    "\n",
    "# Make app layout\n",
    "app.layout = html.Div(\n",
    "    [# Titles\n",
    "        html.Div([\n",
    "            html.Img(\n",
    "                src=\"http://fchen.info/wp-content/uploads/2016/10/fclogo2.png\",\n",
    "                className='five columns',\n",
    "                style={\n",
    "                    'height': '60',\n",
    "                    'width': '60',\n",
    "                    'float': 'left',\n",
    "                    'text-align': 'center'\n",
    "                },\n",
    "            ),\n",
    "            html.H1(\n",
    "                'Earnings Checking Tool',\n",
    "                className='seven columns',\n",
    "                style={'text-align': 'center'}\n",
    "            ),\n",
    "        ],\n",
    "            className='row'\n",
    "        ),\n",
    "        # First Row\n",
    "        html.Hr(style={'margin': '0', 'margin-bottom': '5'}),\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.Label('Historical Data Checking:'),\n",
    "                html.Div([\n",
    "                    html.Label('Lookback Window:'),\n",
    "                    dcc.Slider(\n",
    "                        id='lookback-slider',\n",
    "                        min = 100,\n",
    "                        max = 10000,\n",
    "                        value = 500,\n",
    "                    ),\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'}),\n",
    "                html.Div([\n",
    "                    html.Label('Days for Volatility Calculation:'),\n",
    "                    dcc.Slider(\n",
    "                        marks={i: '{}'.format(i) for i in range(5,30)},\n",
    "                        id='voldays-slider',\n",
    "                        min = 5,\n",
    "                        max = 30,\n",
    "                        value = 20,\n",
    "                    )\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'}),\n",
    "                \n",
    "                html.Div([\n",
    "                    html.Label('Ticker Lookup'),\n",
    "                    dcc.Input(id='ticker-input', type='text', value='AAPL')\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'}),\n",
    "                \n",
    "                html.Div([\n",
    "                    html.Label('Histogram Field'),\n",
    "                    dcc.Dropdown(\n",
    "                            id='hist-dropdown',\n",
    "                            options=plotfields,\n",
    "                            value='price_dev',\n",
    "                    )\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'}),\n",
    "                \n",
    "                html.Button(id='submit-ticker', n_clicks=0, children='Ticker Lookup')\n",
    "            ],\n",
    "                className='eight columns',\n",
    "            ),\n",
    "            html.Div([\n",
    "                \n",
    "                html.Div([\n",
    "                    html.Label('Earnings Date:'),\n",
    "                    dcc.DatePickerSingle(\n",
    "                        id='earnings-date',\n",
    "                        date=dt.datetime(2018, 2, 26)\n",
    "                    ),\n",
    "                    html.Button(id='submit-yahoo', n_clicks=0, children='Update Date')\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'}),\n",
    "                                \n",
    "                html.Div([\n",
    "                    html.Label('Call Time Filter:'),\n",
    "                    dcc.RadioItems(\n",
    "                        id='open_close_selector',\n",
    "                        options=[\n",
    "                            {'label': 'Before Market Open', 'value': 'Before Market Open'},\n",
    "                            {'label': 'After Market Close', 'value': 'After Market Close'},\n",
    "                        ],\n",
    "                        value = 'Before Market Open',\n",
    "                        labelStyle={'display': 'inline-block'},\n",
    "                    ),\n",
    "                    html.Button(id='submit-filter', n_clicks=0, children='Call Time Update')\n",
    "                ],\n",
    "                className = 'row',\n",
    "                style={'padding': '3%'})\n",
    "            ],\n",
    "                className='four columns',\n",
    "            )\n",
    "        ],\n",
    "            className='row',\n",
    "            style={'margin-bottom': '1%'}\n",
    "        ),\n",
    "        \n",
    "                \n",
    "        ## Second Row\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.Div([\n",
    "                    dcc.Graph(id = 'return-distribution', style={'max-height': '450', 'height': '60vh'})\n",
    "                ],\n",
    "                    className = 'row'),\n",
    "                html.Div([\n",
    "                    dcc.Graph(id = 'return-history', style={'max-height': '450', 'height': '60vh'})\n",
    "                ],\n",
    "                    className = 'row'),\n",
    "                html.Div(id = 'largest-drop', className = 'row'),\n",
    "                html.Div(id = 'largest-spike', className = 'row')\n",
    "            ],\n",
    "                className='eight columns'\n",
    "            ),\n",
    "            html.Div(id = 'worst-table', className = 'four columns')\n",
    "        ],\n",
    "            className='row',\n",
    "            style={'margin-bottom': '2%'}\n",
    "        ),\n",
    "        \n",
    "        \n",
    "        # Temporary hack for live dataframe caching\n",
    "        # 'hidden' set to 'loaded' triggers next callback\n",
    "        html.P(\n",
    "            hidden='',\n",
    "            id='earnings-data',\n",
    "            style={'display': 'none'}\n",
    "        )\n",
    "    ],\n",
    "    style={\n",
    "        'width': '85%',\n",
    "        'max-width': '1200',\n",
    "        'margin-left': 'auto',\n",
    "        'margin-right': 'auto',\n",
    "        'font-family': 'overpass',\n",
    "        'background-color': '#FFFFFF',\n",
    "        'padding': '40',\n",
    "        'padding-top': '20',\n",
    "        'padding-bottom': '20',\n",
    "    },\n",
    ")\n",
    "\n",
    "# Cache raw data\n",
    "# Callback function to load worst return recalculated data\n",
    "# into global worst_return_data for useage\n",
    "@app.callback(Output('earnings-data', 'hidden'),\n",
    "              [Input('submit-yahoo', 'n_clicks')],\n",
    "              [State('earnings-date', 'date')])\n",
    "def cache_raw_data(n_clicks, datepick):\n",
    "    date_string = dt.datetime.strptime(datepick, '%Y-%m-%d')    \n",
    "    global earnings_table\n",
    "    earnings_table = yahoo_earnings(date_string)\n",
    "    \n",
    "    print('Loaded raw data')\n",
    "\n",
    "    return 'Earnings loaded'\n",
    "\n",
    "@app.callback(Output('worst-table', 'children'),\n",
    "              [Input('submit-filter', 'n_clicks')],\n",
    "              [State('open_close_selector', 'value')])\n",
    "def earnings_table_data(n_clicks, calltime):\n",
    "    last_closes = close_data(earnings_table['Tickers'].tolist()).tail(1)\n",
    "    last_closes = np.round(last_closes.transpose(),2)\n",
    "    last_closes.columns = ['Close']\n",
    "    last_closes['Tickers'] = last_closes.index\n",
    "    output_table = earnings_table.merge(last_closes, on=['Tickers'], how='left')\n",
    "    output_table['Implied Down Price'] = np.round((1 - output_table['Current 7 Day Implied'].apply(pd.to_numeric)/100)*output_table['Close'],2)\n",
    "    \n",
    "    return generate_table(output_table[output_table['Call Times'] == calltime])\n",
    "\n",
    "# Callback function for yahoo latest options data\n",
    "@app.callback(Output('return-distribution', 'figure'),\n",
    "              [Input('submit-ticker', 'n_clicks')],\n",
    "              [State('ticker-input', 'value'),\n",
    "               State('lookback-slider', 'value'),\n",
    "               State('voldays-slider', 'value'),\n",
    "               State('hist-dropdown', 'value')])\n",
    "def update_histogram(n_clicks, ticker, lookbackwindow, rollingperiod, histfield):\n",
    "    \n",
    "    global retdata\n",
    "    retdata = price_devs(ticker, lookbackwindow, rollingperiod)[histfield].dropna()\n",
    "\n",
    "    trace1 = go.Histogram(\n",
    "        x=retdata,\n",
    "        histnorm='count',\n",
    "        name='control',\n",
    "#         xbins=dict(\n",
    "#             start=-2.0,\n",
    "#             end=2.0,\n",
    "#             size=0.001\n",
    "#         ),\n",
    "        opacity=0.75\n",
    "    )\n",
    "\n",
    "    data = [trace1]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title= ticker + ' Return Distribution',\n",
    "        xaxis=dict(\n",
    "            title=histfield\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Count'\n",
    "        ),\n",
    "        bargap=0.2,\n",
    "        bargroupgap=0.1\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "# Callback function for yahoo latest options data\n",
    "@app.callback(Output('return-history', 'figure'),\n",
    "              [Input('submit-ticker', 'n_clicks')],\n",
    "              [State('ticker-input', 'value')])\n",
    "def update_bar(n_clicks, ticker):\n",
    "    \n",
    "    trace1 = go.Bar(\n",
    "        x=retdata.index,\n",
    "        y=retdata.values,\n",
    "        name=retdata.name\n",
    "    )\n",
    "\n",
    "    data = [trace1]\n",
    "    layout = go.Layout(\n",
    "        title=ticker + ' Historical Profile',\n",
    "        xaxis=dict(\n",
    "            title = 'Date',\n",
    "            tickfont=dict(\n",
    "                size=14\n",
    "            )\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=retdata.name,\n",
    "            titlefont=dict(\n",
    "                size=16\n",
    "            ),\n",
    "            tickfont=dict(\n",
    "                size=14\n",
    "            )\n",
    "        ),\n",
    "        bargap=0.15\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "# Callback function for yahoo latest options data\n",
    "@app.callback(Output('largest-drop', 'children'),\n",
    "              [Input('submit-ticker', 'n_clicks')],\n",
    "              [State('ticker-input', 'value')])\n",
    "def update_large_drop(n_clicks, ticker):\n",
    "    \n",
    "    # Finding date of largest drop\n",
    "    dropstring = '''\n",
    "    Largest drop for {2} was {0} and occured on {1}\n",
    "    '''.format(np.round(retdata.iloc[retdata.index.get_loc(retdata.idxmin())], 2),\n",
    "               retdata.idxmin().strftime('%Y-%m-%d'),\n",
    "               ticker)   \n",
    "    \n",
    "    return dropstring\n",
    "\n",
    "# Callback function for yahoo latest options data\n",
    "@app.callback(Output('largest-spike', 'children'),\n",
    "              [Input('submit-ticker', 'n_clicks')],\n",
    "              [State('ticker-input', 'value')])\n",
    "def update_large_spike(n_clicks, ticker):\n",
    "    \n",
    "    # Finding date of largest drop\n",
    "    spikestring = '''\n",
    "    Largest Spike for {2} was {0} and occured on {1}\n",
    "    '''.format(np.round(retdata.iloc[retdata.index.get_loc(retdata.idxmax())], 2),\n",
    "               retdata.idxmax().strftime('%Y-%m-%d'),\n",
    "               ticker)\n",
    "    \n",
    "    return spikestring\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
