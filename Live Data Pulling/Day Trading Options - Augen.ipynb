{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note to import from .py files, must follow structure\n",
    "# from <.py filename excluding '.py'> import <class name>\n",
    "# Optionslam creds: aspringfastlaner Options2018\n",
    "\n",
    "# Importing necessary models\n",
    "import smtplib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas.stats.moments as st\n",
    "from pandas import ExcelWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as dates\n",
    "# import matplotlib.ticker as ticker\n",
    "from lxml import html\n",
    "import requests\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import csv\n",
    "import sched, time\n",
    "import pandas_datareader as datareader\n",
    "from pandas_datareader.data import Options\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "from py_vollib.black_scholes import implied_volatility\n",
    "'''\n",
    "Calculate the Black-Scholes implied volatility.\n",
    "\n",
    "Parameters:\t\n",
    "price (float) – the Black-Scholes option price\n",
    "S (float) – underlying asset price\n",
    "K (float) – strike price\n",
    "t (float) – time to expiration in years\n",
    "r (float) – risk-free interest rate\n",
    "flag (str) – ‘c’ or ‘p’ for call or put.\n",
    ">>> S = 100\n",
    ">>> K = 100\n",
    ">>> sigma = .2\n",
    ">>> r = .01\n",
    ">>> flag = 'c'\n",
    ">>> t = .5\n",
    ">>> price = black_scholes(flag, S, K, t, r, sigma)\n",
    ">>> iv = implied_volatility(price, S, K, t, r, flag)\n",
    "'''\n",
    "%matplotlib inline\n",
    "\n",
    "# Alpha Vantage API Key\n",
    "# 5HZEUI5AFJB06BUK\n",
    "\n",
    "# ts = TimeSeries(key='5HZEUI5AFJB06BUK', output_format='pandas')\n",
    "# data, meta_data = ts.get_intraday(symbol='MSFT',interval='1min', outputsize='full')\n",
    "# data['close'].plot()\n",
    "# plt.title('Intraday Times Series for the MSFT stock (1 min)')\n",
    "# For intraday\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=MSFT&interval=1min&apikey=d5HZEUI5AFJB06BUK&datatype=csv\n",
    "\n",
    "# For daily\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&apikey=5HZEUI5AFJB06BUK&datatype=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Pulling S&P 500 Names\n",
    "'''\n",
    "\n",
    "def pull_sp500_list():\n",
    "    site = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    table = soup.find_all('table')[0]\n",
    "\n",
    "    tickers = []\n",
    "    names = []\n",
    "    gics = []\n",
    "\n",
    "    # Looping through the soup lxml text table format\n",
    "    # and splitting each row as a individual string\n",
    "    # and parsing string to retrieve the date,\n",
    "    # open, and close information.\n",
    "    i = 1\n",
    "    for row in table.find_all('tr'):\n",
    "        if i == 1:\n",
    "            i += 1\n",
    "            continue\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        # row_items is parsed string for each current row where each\n",
    "        ticker = individual_row[1].split('\">')[-1].split('<')[0]\n",
    "        tickers.append(ticker)\n",
    "        name = individual_row[2].split('\">')[-1].split('<')[0]\n",
    "        names.append(name)\n",
    "        gic = individual_row[4].split('>')[1].split('<')[0]\n",
    "        gics.append(gic)\n",
    "\n",
    "    sp500 = pd.DataFrame({'Name': names, 'GIC': gics}, index = tickers)\n",
    "    sp500.index.name = 'Tickers'\n",
    "    return sp500\n",
    "\n",
    "nasdaq = pd.read_csv('http://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NASDAQ&render=download', index_col = 0)[['Name','LastSale','IPOyear','Sector']]\n",
    "nyse = pd.read_csv('http://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NYSE&render=download', index_col = 0)[['Name','LastSale','IPOyear','Sector']]\n",
    "us_stocks = pd.concat([nyse,nasdaq], axis = 0).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for pulling implied volatility from option slam for single ticker\n",
    "'''\n",
    "\n",
    "def optionslam_scrape(ticker):\n",
    "    site = 'https://www.optionslam.com/earnings/stocks/' + ticker\n",
    "    res = requests.get(site)\n",
    "    soup = bs(requests.get(site).text, \"lxml\")\n",
    "    soup = soup.prettify()\n",
    "    earnings_dict = {'Ticker': ticker}\n",
    "    \n",
    "    # Check if there's weekly options\n",
    "    curr7_implied = \"Current 7 Day Implied Movement:\"\n",
    "    implied_move_weekly = \"Implied Move Weekly:\"\n",
    "    nextearnings = \"Next Earnings Date:\"\n",
    "    if curr7_implied not in soup:\n",
    "        return 'No Weeklies'\n",
    "    \n",
    "    # Parsing if weekly options exist\n",
    "    # Next earnings date and before or after\n",
    "    earnings_start_string = \"Next Earnings Date:\"\n",
    "    earnings_end_string = '</font>'\n",
    "    raw_earnings_string = (soup.split(earnings_start_string))[1].split(earnings_end_string)[0].replace('\\n','').strip()\n",
    "    \n",
    "    try:\n",
    "        earnings_date = str((raw_earnings_string.split('<b>'))[1].split('<font size=\"-1\">')).split(\"'\")[1].strip()\n",
    "    except:\n",
    "        return 'Error Parsing'\n",
    "    \n",
    "    earnings_time = str(raw_earnings_string[-2:].strip()).strip()\n",
    "    \n",
    "    earnings_dict['Date'] = earnings_date\n",
    "    earnings_dict['Earnings Time'] = earnings_time\n",
    "    \n",
    "    # Parsing 7 day implied move if weekly option exists\n",
    "    ending_string = '<font size=\"-2\">'\n",
    "    curr_7 = (soup.split(curr7_implied))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    earnings_dict['Current 7 Day Implied'] = curr_7\n",
    "    \n",
    "    # Parsing Weekly Implied move if weekly option exists\n",
    "    if implied_move_weekly in soup:\n",
    "        weekly_implied = (soup.split(implied_move_weekly))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    else:\n",
    "        weekly_implied = ''\n",
    "    earnings_dict[\"Implied Move Weekly\"] = weekly_implied\n",
    "    \n",
    "    return earnings_dict\n",
    "\n",
    "# Function for calculating standard dev and price moves in terms of standard dev\n",
    "# DF[[Adj Close]] Rolling Period --> DF[['Daily Vol','Daily Price Vol','Price Dev','Annual Vol']]\n",
    "def price_devs(ticker, lookbackwindow, rollingperiod):\n",
    "    # Define which online source one should use\n",
    "    data_source = 'yahoo'\n",
    "    \n",
    "    end = dt.datetime.today()\n",
    "    start_date = end - dt.timedelta(days = lookbackwindow)\n",
    "    \n",
    "    # User pandas_reader.data.DataReader to load the desired data. As simple as that.\n",
    "    df = datareader.DataReader([ticker], data_source, start_date, end).sort_index()\n",
    "\n",
    "    # Getting just the adjusted closing prices. This will return a Pandas DataFrame\n",
    "    # The index in this DataFrame is the major index of the panel_data.\n",
    "    df = df.ix['Close'].sort_index()\n",
    "    \n",
    "    df.columns = ['prices']\n",
    "    df['prices_delta'] = df.prices - df.prices.shift(1)\n",
    "    df['log_returns'] = np.log(df.prices) - np.log(df.prices.shift(1))\n",
    "    df['daily_vol'] = st.rolling_std(df.log_returns, rollingperiod, ddof = 1)\n",
    "    df['daily_vol_dollar'] = df.daily_vol*df.prices\n",
    "    df['price_dev'] = df.prices_delta/df.daily_vol_dollar.shift(1)\n",
    "    df['annual_vol'] = df.daily_vol*np.sqrt(252)\n",
    "    return df\n",
    "\n",
    "\n",
    "'''\n",
    "Functions for pulling options data from yahoo Input is a string. The output is a dataframe of the latest\n",
    "data from yahoo finance tagged with the current date-time. Output columns are pull date-time,\n",
    "contract name, strike, last price, bid, ask volume, open interest, and IV (in decimal form).\n",
    "'''\n",
    "ticker = 'NTES'\n",
    "\n",
    "# Function for initial querying of yahoo data\n",
    "def yahoo_option_query(ticker, unix_date):\n",
    "    # dt.datetime.fromtimestamp(1525996800).date()\n",
    "    if unix_date == 'None':\n",
    "        yahoo_query = 'https://query1.finance.yahoo.com/v7/finance/options/{0}'.format(ticker)\n",
    "    else:\n",
    "        yahoo_query = 'https://query1.finance.yahoo.com/v7/finance/options/{0}?date={1}'.format(ticker,str(unix_date))\n",
    "        \n",
    "    response = urllib.request.urlopen(yahoo_query)\n",
    "    data = json.loads(response.read().decode())['optionChain']['result'][0]\n",
    "    \n",
    "    dict_lst = []\n",
    "    for key in data.keys():\n",
    "        dict_lst.append(data[key])\n",
    "        \n",
    "    expiries = dict_lst[1]\n",
    "    strikes = dict_lst[2]\n",
    "    underlying = dict_lst[4]\n",
    "    calls = dict_lst[5][0]['calls']\n",
    "    puts = dict_lst[5][0]['puts']\n",
    "    \n",
    "    return (expiries, strikes, underlying, calls, puts)\n",
    "\n",
    "# Function for creating dataframe for options contracts for a specific maturity date\n",
    "def create_contract_df(option_dict_lst, strikes):\n",
    "    df = pd.DataFrame(columns = ['lastPrice','volume','openInterest','bid','ask','mid','impliedVolatility','expiration'],\n",
    "                      index = strikes)\n",
    "    for contract in option_dict_lst:\n",
    "        for col in df.columns:\n",
    "            if col == 'expiration':\n",
    "                df.loc[contract['strike'], col] = (dt.datetime.fromtimestamp(contract['expiration']) - dt.datetime.today()).days\n",
    "            elif col == 'mid':\n",
    "                df.loc[contract['strike'], col] = contract['ask'] - contract['bid']\n",
    "            else:\n",
    "                df.loc[contract['strike'], col] = contract[col]\n",
    "    return df.dropna()\n",
    "\n",
    "# Function for creating straddle view of options for a specific date\n",
    "def option_chain(puts, calls, strikes):\n",
    "    call_contracts = create_contract_df(calls, strikes)\n",
    "    put_contracts = create_contract_df(puts, strikes)\n",
    "    return call_contracts.join(put_contracts, how = 'inner', lsuffix='_c', rsuffix='_p')\n",
    "\n",
    "# Function for getting full option data for a specific ticker\n",
    "def pull_options(ticker):\n",
    "    initial_near_contract = yahoo_option_query(ticker, 'None')\n",
    "    \n",
    "    expiries = initial_near_contract[0]\n",
    "    options_list = [option_chain(initial_near_contract[3], initial_near_contract[4], initial_near_contract[1])]\n",
    "    \n",
    "    for expiry in expiries:\n",
    "        next_contract = yahoo_option_query(ticker, expiry)\n",
    "        options_list.append([option_chain(next_contract[3], next_contract[4], next_contract[1])])\n",
    "        \n",
    "    return pd.concat(options_list, axis = 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "def fundamentals(ticker):\n",
    "    \n",
    "    site = 'https://finance.yahoo.com/quote/{0}?p={0}'.format(ticker)\n",
    "\n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    table = soup.find_all('table')[1]\n",
    "    sum_dict = {}\n",
    "\n",
    "    # Looping through the soup lxml text table format\n",
    "    # and splitting each row as a individual string\n",
    "    # and parsing string to retrieve the date,\n",
    "    # open, and close information.\n",
    "\n",
    "\n",
    "    for row in table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')[0]\n",
    "\n",
    "        # row_items is parsed string for each current row where each\n",
    "        # item in list is the date, open, high, low, close, and volume\n",
    "        row_items = individual_row.split('<span data-reactid=')[1].split('\"><!-- react-text: ')\n",
    "        if len(row_items) > 1:\n",
    "            sum_item = row_items[0].split('>')[1].split('<')[0]\n",
    "            sum_value = row_items[1].split('-->')[1].split('<')[0]\n",
    "        elif 'YIELD' in row_items[0]:\n",
    "            try:\n",
    "                temp_val = row_items[0].split('-value\">')[1].split(\"</td>\")[0]\n",
    "                div_amount = float(temp_val.split(' ')[0])\n",
    "                div_yield = float(temp_val.split(' ')[1].replace('(','').replace(')','').replace('%',''))\n",
    "\n",
    "                sum_dict['Div'] = div_amount\n",
    "                sum_dict['Yield'] = div_yield\n",
    "            except:\n",
    "                sum_dict['Div'] = np.nan\n",
    "                sum_dict['Yield'] = np.nan\n",
    "\n",
    "        sum_dict[sum_item] = sum_value\n",
    "\n",
    "    return pd.DataFrame(sum_dict, index = [ticker])\n",
    "\n",
    "# Function to return fundametal data of a ticker list\n",
    "def get_fundas(ticker_lst):\n",
    "    fund_lst = []\n",
    "    for tick in ticker_lst:\n",
    "        fund_lst.append(fundamentals(tick))\n",
    "    return pd.concat(fund_lst,axis = 0)\n",
    "\n",
    "# Function to pull straddled view of options of a ticker\n",
    "def get_option_chain(ticker, date):\n",
    "    putframe = yahoo_options(date, contract = 'put', ticker = ticker)\n",
    "    callframe = yahoo_options(date, contract = 'call', ticker = ticker)\n",
    "    calls = callframe[['Ask','Bid','Implied Volatility','Last Price','Open Interest','Strike','Volume']]\n",
    "    puts = putframe[['Ask','Bid','Implied Volatility','Last Price','Open Interest','Strike','Volume']]\n",
    "    return puts.merge(calls, how = 'inner', on = 'Strike', suffixes=('_C', '_P'))\n",
    "\n",
    "# Function historical data from alpha advantage\n",
    "def historical_data(ticker, window = 252, outsize = 'full'):\n",
    "    alphavantage_link = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={0}&apikey=5HZEUI5AFJB06BUK&datatype=csv&outputsize={1}'.format(ticker, outsize)\n",
    "    stockframe = pd.read_csv(alphavantage_link, index_col = 0).sort_index()[['open', 'close']]\n",
    "    stockframe['daily_ret'] = np.log(stockframe['close']/stockframe['close'].shift(1))\n",
    "    stockframe['intra_ret'] = np.log(stockframe['close']/stockframe['open'])\n",
    "    stockframe['ovrnt_ret'] = np.log(stockframe['open']/stockframe['close'].shift(1))\n",
    "    stockframe['daily_vol'] = stockframe.daily_ret.rolling(window=20,center=False).std()\n",
    "    stockframe['intra_vol'] = stockframe.intra_ret.rolling(window=20,center=False).std()\n",
    "    stockframe['ovrnt_vol'] = stockframe.ovrnt_ret.rolling(window=20,center=False).std()\n",
    "    stockframe['daily_ann'] = stockframe.daily_vol*np.sqrt(252)\n",
    "    stockframe['intra_ann'] = stockframe.intra_vol*np.sqrt((24/6.5)*252)\n",
    "    stockframe['ovrnt_ann'] = stockframe.ovrnt_vol*np.sqrt((24/17.5)*252)\n",
    "    stockframe['oc_diff'] = stockframe.close - stockframe.open\n",
    "    stockframe['daily_dollar_vol'] = stockframe.daily_vol*stockframe.close.shift(1)\n",
    "    stockframe['daily_dollar_std'] = np.abs(stockframe.oc_diff/stockframe.daily_dollar_vol)\n",
    "\n",
    "    return stockframe.tail(window)\n",
    "\n",
    "# Function for building a dataframe of volatilities\n",
    "# Daily, Intraday, Overnight\n",
    "def current_volatility(ticker_list):\n",
    "    \n",
    "    rows = []\n",
    "    for tick in ticker_list:\n",
    "        try:\n",
    "            curr_vol = historical_data(tick, window = 1, outsize = 'compact')[['daily_ann','intra_ann','ovrnt_ann']]\n",
    "            curr_vol.index.name = 'Tickers'\n",
    "            curr_vol.index = [tick]\n",
    "            rows.append(curr_vol)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    return pd.concat(rows, axis = 0)\n",
    "\n",
    "# Function for pulling S&P500 data and calculating volatilities\n",
    "def sp500_filter():\n",
    "    sp500 = pull_sp500_list()\n",
    "    sp500_vols = current_volatility(sp500.index.tolist())\n",
    "    df = pd.concat([sp500_vols, sp500], axis = 1).dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us_vol = current_volatility(us_stocks.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp500_len = len(sp500)\n",
    "end_range = 100\n",
    "start_range = 0\n",
    "i = 0\n",
    "batch_list = []\n",
    "while sp500_len > 100:\n",
    "    tick_lst = sp500[start_range:end_range].index.tolist()\n",
    "    tickers = str(tick_lst).replace('[','').replace(']','').replace(\"'\",\"\").replace(\" \",\"\")\n",
    "    alphavantage_link = 'https://www.alphavantage.co/query?function=BATCH_STOCK_QUOTES&symbols={0}&apikey=5HZEUI5AFJB06BUK&datatype=csv'.format(tickers)\n",
    "    batch_list.append(pd.read_csv(alphavantage_link, index_col = 0)[['price']])\n",
    "    start_range = end_range\n",
    "    end_range = end_range + 100\n",
    "    sp500_len = sp500_len - 100\n",
    "    i += 1\n",
    "start_range = i*100\n",
    "tick_lst = sp500[start_range:(start_range + sp500_len)].index.tolist()\n",
    "tickers = str(tick_lst).replace('[','').replace(']','').replace(\"'\",\"\").replace(\" \",\"\")\n",
    "alphavantage_link = 'https://www.alphavantage.co/query?function=BATCH_STOCK_QUOTES&symbols={0}&apikey=5HZEUI5AFJB06BUK&datatype=csv'.format(tickers)\n",
    "batch_list.append(pd.read_csv(alphavantage_link, index_col = 0)[['price']])\n",
    "batch_quotes = pd.concat(batch_list, axis = 0)\n",
    "sp500_df = pd.concat([sp500, batch_quotes], axis = 1)\n",
    "sp500_df['Intra_Daily_Ratio'] = sp500_df['intra_ann']/sp500_df['daily_ann']\n",
    "sp500_df = sp500_df.sort_values(['Intra_Daily_Ratio'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntes = pull_options(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(current_volatility(['NTES']))\n",
    "hist = historical_data('NTES')\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
