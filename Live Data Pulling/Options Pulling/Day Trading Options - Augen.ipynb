{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note to import from .py files, must follow structure\n",
    "# from <.py filename excluding '.py'> import <class name>\n",
    "# Optionslam creds: aspringfastlaner Options2018\n",
    "\n",
    "# Importing necessary models\n",
    "import smtplib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas.stats.moments as st\n",
    "from pandas import ExcelWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as dates\n",
    "# import matplotlib.ticker as ticker\n",
    "from lxml import html\n",
    "import requests\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import csv\n",
    "import sched, time\n",
    "import pandas_datareader as datareader\n",
    "from pandas_datareader.data import Options\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "ts = TimeSeries(key='5HZEUI5AFJB06BUK',output_format='pandas')\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request as urlreq\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from pandas_datareader.data import Options\n",
    "import py_vollib\n",
    "from py_vollib.black_scholes_merton.implied_volatility import *\n",
    "from py_vollib.black_scholes_merton.greeks.analytical import *\n",
    "\n",
    "'''\n",
    "Calculate the Black-Scholes implied volatility.\n",
    "\n",
    "Parameters:\t\n",
    "price (float) – the Black-Scholes option price\n",
    "S (float) – underlying asset price\n",
    "K (float) – strike price\n",
    "t (float) – time to expiration in years\n",
    "r (float) – risk-free interest rate\n",
    "flag (str) – ‘c’ or ‘p’ for call or put.\n",
    ">>> S = 100\n",
    ">>> K = 100\n",
    ">>> sigma = .2\n",
    ">>> r = .01\n",
    ">>> flag = 'c'\n",
    ">>> t = .5\n",
    ">>> price = black_scholes(flag, S, K, t, r, sigma)\n",
    ">>> iv = implied_volatility(price, S, K, t, r, flag)\n",
    "'''\n",
    "%matplotlib inline\n",
    "\n",
    "def write_excel(filename, sheetnames, df_list):\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "    for i, df in enumerate(df_list):\n",
    "        \n",
    "        df.to_excel(writer, sheet_name = sheetnames[i])\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()\n",
    "    return\n",
    "\n",
    "# Alpha Vantage API Key\n",
    "# 5HZEUI5AFJB06BUK\n",
    "\n",
    "# ts = TimeSeries(key='5HZEUI5AFJB06BUK', output_format='pandas')\n",
    "# data, meta_data = ts.get_intraday(symbol='MSFT',interval='1min', outputsize='full')\n",
    "# data['close'].plot()\n",
    "# plt.title('Intraday Times Series for the MSFT stock (1 min)')\n",
    "# For intraday\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=MSFT&interval=1min&apikey=d5HZEUI5AFJB06BUK&datatype=csv\n",
    "\n",
    "# For daily\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&apikey=5HZEUI5AFJB06BUK&datatype=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Pulling S&P 500 Names\n",
    "'''\n",
    "\n",
    "def pull_sp500_list():\n",
    "    site = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    table = soup.find_all('table')[0]\n",
    "\n",
    "    tickers = []\n",
    "    names = []\n",
    "    gics = []\n",
    "\n",
    "    # Looping through the soup lxml text table format\n",
    "    # and splitting each row as a individual string\n",
    "    # and parsing string to retrieve the date,\n",
    "    # open, and close information.\n",
    "    i = 1\n",
    "    for row in table.find_all('tr'):\n",
    "        if i == 1:\n",
    "            i += 1\n",
    "            continue\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        # row_items is parsed string for each current row where each\n",
    "        ticker = individual_row[1].split('\">')[-1].split('<')[0]\n",
    "        tickers.append(ticker)\n",
    "        name = individual_row[2].split('\">')[-1].split('<')[0]\n",
    "        names.append(name)\n",
    "        gic = individual_row[4].split('>')[1].split('<')[0]\n",
    "        gics.append(gic)\n",
    "\n",
    "    sp500 = pd.DataFrame({'Name': names, 'GIC': gics}, index = tickers)\n",
    "    sp500.index.name = 'Tickers'\n",
    "    return sp500\n",
    "\n",
    "#nasdaq = pd.read_csv('http://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NASDAQ&render=download', index_col = 0)[['Name','LastSale','IPOyear','Sector']]\n",
    "#nyse = pd.read_csv('http://www.nasdaq.com/screening/companies-by-industry.aspx?exchange=NYSE&render=download', index_col = 0)[['Name','LastSale','IPOyear','Sector']]\n",
    "#us_stocks = pd.concat([nyse,nasdaq], axis = 0).drop_duplicates()\n",
    "#us_stocks = us_stocks[us_stocks['LastSale'] != 'n/a']\n",
    "#us_fundamentals = get_fundas([string.replace(' ','') for string in us_stocks.index.tolist()])\n",
    "us_stocks = pd.read_csv('us_stocks.csv', index_col = 0)\n",
    "\n",
    "active_stocks = pd.read_csv('active_names.csv', index_col = 0).dropna()\n",
    "active_etfs = pd.read_csv('active_etfs.csv', index_col = 0).dropna()\n",
    "highest_ivs = pd.read_csv('highest_iv.csv', index_col = 0).dropna()\n",
    "\n",
    "# filtered_names = pd.read_csv('filtered_names.csv', index_col = 0).join(us_stocks, how = 'inner')[us_stocks.columns]\n",
    "# filtered_names['Market Cap'] = filtered_names['Market Cap'].astype(str).str[:-1]\n",
    "# filtered_names['Market Cap'] = filtered_names['Market Cap'].astype(float)\n",
    "# filtered_names = filtered_names.sort_values(['Market Cap'], ascending = False)\n",
    "\n",
    "watchlist = ['NVDA', 'FB', 'AMZN', 'NFLX', 'GOOGL', 'GOOG',\n",
    "             'TSLA', 'EA', 'ATVI', 'APPL', 'MSFT', 'INTC',\n",
    "             'V', 'CSCO', 'VZ', 'T', 'MA', 'ORCL', 'IBM',\n",
    "             'ADBE', 'TXN', 'AVGO', 'PYPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for pulling implied volatility from option slam for single ticker\n",
    "'''\n",
    "\n",
    "def optionslam_scrape(ticker):\n",
    "    site = 'https://www.optionslam.com/earnings/stocks/' + ticker\n",
    "    res = requests.get(site)\n",
    "    soup = bs(requests.get(site).text, \"lxml\")\n",
    "    soup = soup.prettify()\n",
    "    earnings_dict = {'Ticker': ticker}\n",
    "    \n",
    "    # Check if there's weekly options\n",
    "    curr7_implied = \"Current 7 Day Implied Movement:\"\n",
    "    implied_move_weekly = \"Implied Move Weekly:\"\n",
    "    nextearnings = \"Next Earnings Date:\"\n",
    "    if curr7_implied not in soup:\n",
    "        return 'No Weeklies'\n",
    "    \n",
    "    # Parsing if weekly options exist\n",
    "    # Next earnings date and before or after\n",
    "    earnings_start_string = \"Next Earnings Date:\"\n",
    "    earnings_end_string = '</font>'\n",
    "    raw_earnings_string = (soup.split(earnings_start_string))[1].split(earnings_end_string)[0].replace('\\n','').strip()\n",
    "    \n",
    "    try:\n",
    "        earnings_date = str((raw_earnings_string.split('<b>'))[1].split('<font size=\"-1\">')).split(\"'\")[1].strip()\n",
    "    except:\n",
    "        return 'Error Parsing'\n",
    "    \n",
    "    earnings_time = str(raw_earnings_string[-2:].strip()).strip()\n",
    "    \n",
    "    earnings_dict['Date'] = earnings_date\n",
    "    earnings_dict['Earnings Time'] = earnings_time\n",
    "    \n",
    "    # Parsing 7 day implied move if weekly option exists\n",
    "    ending_string = '<font size=\"-2\">'\n",
    "    curr_7 = (soup.split(curr7_implied))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    earnings_dict['Current 7 Day Implied'] = curr_7\n",
    "    \n",
    "    # Parsing Weekly Implied move if weekly option exists\n",
    "    if implied_move_weekly in soup:\n",
    "        weekly_implied = (soup.split(implied_move_weekly))[1].split(ending_string)[0].replace('\\n','').strip(\"\").split(\"<td>\")[-1].strip()\n",
    "    else:\n",
    "        weekly_implied = ''\n",
    "    earnings_dict[\"Implied Move Weekly\"] = weekly_implied\n",
    "    \n",
    "    return earnings_dict\n",
    "\n",
    "# Looping through the soup lxml text table format\n",
    "# and splitting each row as a individual string\n",
    "# and parsing string to retrieve the date,\n",
    "# open, and close information.\n",
    "\n",
    "def yahoo_table_parse(raw_html_table):\n",
    "    tickers = []\n",
    "    call_times = []\n",
    "    implied_7_day = []\n",
    "    implied_weekly = []\n",
    "    eps = []\n",
    "    i = 1\n",
    "    end_row = 10\n",
    "    for row in raw_html_table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')\n",
    "        row_items = individual_row[0].split('</span>')[:3]\n",
    "\n",
    "        if i == 1:\n",
    "            i += 1\n",
    "            continue\n",
    "        tick = row_items[0].split('data-symbol=\"')[1].split('\"')[0]\n",
    "        os_check = optionslam_scrape(tick)\n",
    "\n",
    "        if type(os_check) == str:\n",
    "            continue\n",
    "        else:\n",
    "            tickers.append(tick)\n",
    "            call_times.append(row_items[0].split('data-symbol=\"')[1].split('\"')[-1].replace('>',''))\n",
    "            eps.append(row_items[1].split('</td>')[1].split('>')[1])\n",
    "            implied_7_day.append(os_check['Current 7 Day Implied'].replace('%',''))\n",
    "            implied_weekly.append(os_check['Implied Move Weekly'].replace('%',''))\n",
    "\n",
    "\n",
    "    return pd.DataFrame({'Tickers': tickers, 'Call Times': call_times, 'EPS': eps,\n",
    "                         'Current 7 Day Implied': implied_7_day,\n",
    "                         'Implied Move Weekly': implied_weekly})\n",
    "\n",
    "\n",
    "def yahoo_earnings(date):\n",
    "    # Yahoo Earnings Calendar Check\n",
    "\n",
    "    today = date.strftime('%Y-%m-%d')\n",
    "    tables = []\n",
    "    for i in range(6):\n",
    "        yahoo_url = 'https://finance.yahoo.com/calendar/earnings?day=' + today + '&offset={}&size=100'.format(int(i*100))\n",
    "        res = requests.get(yahoo_url)\n",
    "        soup = bs(requests.get(yahoo_url).text, \"lxml\")\n",
    "\n",
    "        try:\n",
    "            table = soup.find_all('table')[0]\n",
    "            tables.append(yahoo_table_parse(table))\n",
    "        except:\n",
    "            print('No Table')\n",
    "\n",
    "    return pd.concat(tables,axis = 0, ignore_index = True)\n",
    "\n",
    "'''\n",
    "Functions for pulling options data from yahoo Input is a string. The output is a dataframe of the latest\n",
    "data from yahoo finance tagged with the current date-time. Output columns are pull date-time,\n",
    "contract name, strike, last price, bid, ask volume, open interest, and IV (in decimal form).\n",
    "'''\n",
    "# Function for initial querying of yahoo data\n",
    "def yahoo_option_query(ticker, unix_date):\n",
    "    # dt.datetime.fromtimestamp(1525996800).date()\n",
    "    if unix_date == 'None':\n",
    "        yahoo_query = 'https://query1.finance.yahoo.com/v7/finance/options/{0}'.format(ticker)\n",
    "    else:\n",
    "        yahoo_query = 'https://query1.finance.yahoo.com/v7/finance/options/{0}?date={1}'.format(ticker,str(unix_date))\n",
    "        \n",
    "    response = urlreq.urlopen(yahoo_query)\n",
    "    data = json.loads(response.read().decode())['optionChain']['result'][0]\n",
    "    \n",
    "    dict_lst = []\n",
    "    for key in data.keys():\n",
    "        dict_lst.append(data[key])\n",
    "        \n",
    "    expiries = dict_lst[1]\n",
    "    strikes = dict_lst[2]\n",
    "    underlying = dict_lst[4]\n",
    "    calls = dict_lst[5][0]['calls']\n",
    "    puts = dict_lst[5][0]['puts']\n",
    "    \n",
    "    return (expiries, strikes, underlying, calls, puts)\n",
    "\n",
    "# Function for creating dataframe for options contracts for a specific maturity date\n",
    "def create_contract_df(option_dict_lst, strikes):\n",
    "    df = pd.DataFrame(columns = ['lastPrice','volume','openInterest','bid','ask','mid','impliedVolatility','expiration'],\n",
    "                      index = strikes)\n",
    "    for contract in option_dict_lst:\n",
    "        for col in df.columns:\n",
    "            if col == 'expiration':\n",
    "                df.loc[contract['strike'], col] = (dt.datetime.fromtimestamp(contract['expiration']) - dt.datetime.today()).days\n",
    "            elif col == 'mid':\n",
    "                df.loc[contract['strike'], col] = (contract['ask'] + contract['bid'])/2\n",
    "            else:\n",
    "                df.loc[contract['strike'], col] = contract[col]\n",
    "    return df.dropna()\n",
    "\n",
    "# Function for creating straddle view of options for a specific date\n",
    "def option_chain(calls, puts, strikes):\n",
    "    call_contracts = create_contract_df(calls, strikes)\n",
    "    put_contracts = create_contract_df(puts, strikes)\n",
    "    return call_contracts.join(put_contracts, how = 'inner', lsuffix='_c', rsuffix='_p')\n",
    "\n",
    "# Function for getting full option data for a specific ticker\n",
    "def pull_options(ticker):\n",
    "    initial_near_contract = yahoo_option_query(ticker, 'None')\n",
    "    \n",
    "    expiries = initial_near_contract[0]\n",
    "    options_list = [option_chain(initial_near_contract[3], initial_near_contract[4], initial_near_contract[1])]\n",
    "    \n",
    "    for expiry in expiries[1:]:\n",
    "        next_contract = yahoo_option_query(ticker, expiry)\n",
    "        options_list.append(option_chain(next_contract[3], next_contract[4], next_contract[1]))\n",
    "        \n",
    "    return pd.concat(options_list, axis = 0)\n",
    "# ts.get_daily('AAPL')[0].tail(1)['close'][0]\n",
    "'''\n",
    "Function for getting all relevant earnings for a given starting week (Monday in dt.datetime(YYYY, m, d) format)\n",
    "Returns a dataframe with the earnings names, implied move, price, and earnings times.\n",
    "'''\n",
    "def weekly_earnings_check(start_datetime, days_forward):\n",
    "\n",
    "    start_date = start_datetime\n",
    "\n",
    "    weekly_earnings = []\n",
    "    while start_date.weekday() < days_forward:\n",
    "        try:\n",
    "            temp_earnings = yahoo_earnings(start_date)\n",
    "            temp_earnings['Earnings Date'] = start_date\n",
    "            temp_earnings['Last Close'] = 0\n",
    "            for idx, row in temp_earnings.iterrows():\n",
    "                temp_earnings.loc[idx, 'Last Close'] = ts.get_daily(row['Tickers'])[0].tail(1)['close'][0]\n",
    "            weekly_earnings.append(temp_earnings)\n",
    "            start_date = start_date + dt.timedelta(1)\n",
    "        except:\n",
    "            start_date = start_date + dt.timedelta(1)\n",
    "\n",
    "    earnings_df = pd.concat(weekly_earnings,axis = 0, ignore_index = True)\n",
    "    earnings_df = earnings_df[earnings_df['Last Close'] >= 30]\n",
    "    earnings_df['Implied Move Weekly'] = pd.to_numeric(earnings_df['Implied Move Weekly'])\n",
    "    #earnings_df = earnings_df[earnings_df['Call Times'] != '-']\n",
    "    earnings_df['Lower Bound'] = np.round(earnings_df['Last Close']*(1 - earnings_df['Implied Move Weekly']/100),2)\n",
    "    earnings_df = earnings_df.sort_values(['Earnings Date','Call Times'])\n",
    "    \n",
    "    return earnings_df\n",
    "\n",
    "def stock_earnings(tick):\n",
    "    yahoo_url = 'https://finance.yahoo.com/calendar/earnings/?symbol={0}'.format(tick)\n",
    "    res = requests.get(yahoo_url).text\n",
    "    res = res.split('table class')[1].split('</table>')[0].split('<tbody data-reactid=\"')[1].split('<td class=\"')\n",
    "    earnings_cols = list(filter(lambda x: 'data-col2' in x, res))\n",
    "    estimate_cols = list(filter(lambda x: 'data-col3' in x, res))\n",
    "    reported_cols = list(filter(lambda x: 'data-col4' in x, res))\n",
    "\n",
    "    earnings_days = []\n",
    "    for i in earnings_cols:\n",
    "        temp_date = i.split('\">')[2].split('</')[0]\n",
    "        temp_date = ''.join(temp_date.split(',')[:-1])\n",
    "        temp_date = dt.datetime.strptime(temp_date, '%b %d %Y')\n",
    "        earnings_days.append(temp_date)\n",
    "\n",
    "    estimate_eps = []\n",
    "    for i in estimate_cols:\n",
    "        try:\n",
    "            temp_est = float(i.split('\">')[1].split('<')[0])\n",
    "        except:\n",
    "            temp_est = np.nan\n",
    "        estimate_eps.append(temp_est)\n",
    "\n",
    "    reported_eps = []\n",
    "    for i in reported_cols:\n",
    "        try:\n",
    "            temp_est = float(i.split('\">')[1].split('<')[0])\n",
    "        except:\n",
    "            temp_est = np.nan\n",
    "        reported_eps.append(temp_est)\n",
    "\n",
    "    earnings = pd.DataFrame({'Earnings Dates': earnings_days,\n",
    "                             'EPS Estimate': estimate_eps,\n",
    "                             'EPS Reported': reported_eps})\n",
    "    return earnings\n",
    "\n",
    "def old_weekly_earnings_check(start_datetime, days_forward):\n",
    "    \n",
    "    def yahoo_earnings_raw(raw_html_table):\n",
    "        tickers = []\n",
    "        eps = []\n",
    "        i = 1\n",
    "        end_row = 10\n",
    "        for row in raw_html_table.find_all('tr'):\n",
    "            # Individual row stores current row item and delimits on '\\n'\n",
    "            individual_row = str(row).split('\\n')\n",
    "            row_items = individual_row[0].split('</span>')[:3]\n",
    "\n",
    "            if i == 1:\n",
    "                i += 1\n",
    "                continue\n",
    "            tick = row_items[0].split('data-symbol=\"')[1].split('\"')[0]\n",
    "            tickers.append(tick)\n",
    "\n",
    "\n",
    "        return pd.DataFrame({'Tickers': tickers})\n",
    "    \n",
    "    def yahoo_earnings_old(date):\n",
    "        # Yahoo Earnings Calendar Check\n",
    "\n",
    "        today = date.strftime('%Y-%m-%d')\n",
    "        tables = []\n",
    "        for i in range(6):\n",
    "            yahoo_url = 'https://finance.yahoo.com/calendar/earnings?day=' + today + '&offset={}&size=100'.format(int(i*100))\n",
    "            res = requests.get(yahoo_url)\n",
    "            soup = bs(requests.get(yahoo_url).text, \"lxml\")\n",
    "\n",
    "            try:\n",
    "                table = soup.find_all('table')[0]\n",
    "                tables.append(yahoo_earnings_raw(table))\n",
    "            except:\n",
    "                print('No Table')\n",
    "\n",
    "        return pd.concat(tables,axis = 0, ignore_index = True)\n",
    "    \n",
    "    start_date = start_datetime\n",
    "\n",
    "    weekly_earnings = []\n",
    "    while start_date.weekday() < days_forward:\n",
    "        try: \n",
    "            temp_earnings = yahoo_earnings_old(start_date)\n",
    "            temp_earnings['Earnings Date'] = start_date\n",
    "            weekly_earnings.append(temp_earnings)\n",
    "            start_date = start_date + dt.timedelta(1)\n",
    "        except:\n",
    "            start_date = start_date + dt.timedelta(1)\n",
    "            continue\n",
    "\n",
    "    earnings_df = pd.concat(weekly_earnings,axis = 0, ignore_index = True)\n",
    "    #earnings_df = earnings_df[earnings_df['Call Times'] != '-']\n",
    "    \n",
    "    return earnings_df\n",
    "\n",
    "    \n",
    "def fundamentals(ticker):\n",
    "    \n",
    "    site = 'https://finance.yahoo.com/quote/{0}?p={0}'.format(ticker)\n",
    "\n",
    "    res = requests.get(site)\n",
    "    soup = bs(res.text, 'lxml')\n",
    "    table = soup.find_all('table')[1]\n",
    "    sum_dict = {}\n",
    "\n",
    "    # Looping through the soup lxml text table format\n",
    "    # and splitting each row as a individual string\n",
    "    # and parsing string to retrieve the date,\n",
    "    # open, and close information.\n",
    "\n",
    "\n",
    "    for row in table.find_all('tr'):\n",
    "        # Individual row stores current row item and delimits on '\\n'\n",
    "        individual_row = str(row).split('\\n')[0]\n",
    "\n",
    "        # row_items is parsed string for each current row where each\n",
    "        # item in list is the date, open, high, low, close, and volume\n",
    "        row_items = individual_row.split('<span data-reactid=')[1].split('\"><!-- react-text: ')\n",
    "        \n",
    "        if len(row_items) > 1:\n",
    "            sum_item = row_items[0].split('>')[1].split('<')[0]\n",
    "            sum_value = row_items[1].split('-->')[1].split('<')[0]\n",
    "        elif 'YIELD' in row_items[0]:\n",
    "            try:\n",
    "                temp_val = row_items[0].split('-value\">')[1].split(\"</td>\")[0]\n",
    "                div_amount = float(temp_val.split(' ')[0])\n",
    "                div_yield = float(temp_val.split(' ')[1].replace('(','').replace(')','').replace('%',''))\n",
    "\n",
    "                sum_dict['Div'] = div_amount\n",
    "                sum_dict['Yield'] = div_yield\n",
    "            except:\n",
    "                sum_dict['Div'] = np.nan\n",
    "                sum_dict['Yield'] = np.nan\n",
    "        elif 'Market Cap' in row_items[0]:\n",
    "            sum_item = 'Market Cap (B)'\n",
    "            mkt_cap = row_items[0].split('data-reactid=\"')[-1].split('>')[1].split('<')[0]\n",
    "            mkt_cap_amount = float(mkt_cap[:-1])\n",
    "            if mkt_cap[-1] == 'M':\n",
    "                sum_value = mkt_cap_amount/1000\n",
    "            else:\n",
    "                sum_value = mkt_cap_amount\n",
    "        else:\n",
    "            sum_item = row_items[0].split('>')[1].split('<')[0]\n",
    "            sum_value = row_items[0].split('data-reactid=\"')[-1].split('>')[1].split('<')[0]\n",
    "        \n",
    "        sum_dict[sum_item] = sum_value\n",
    "    \n",
    "    sum_dict['Days Since Last Earnings'] = (dt.datetime.today().date() - \n",
    "                                            stock_earnings(ticker)['Earnings Dates'][1].date()).days\n",
    "\n",
    "    return pd.DataFrame(sum_dict, index = [ticker])\n",
    "\n",
    "# Function to return fundametal data of a ticker list\n",
    "def get_fundas(ticker_lst):\n",
    "    fund_lst = []\n",
    "    for tick in ticker_lst:\n",
    "        try:\n",
    "            fund_lst.append(fundamentals(tick))\n",
    "        except:\n",
    "            continue\n",
    "    return pd.concat(fund_lst,axis = 0)\n",
    "\n",
    "# Function historical data from alpha advantage\n",
    "def historical_data(ticker, day_number = 252, rolling_window = 20, outsize = 'full'):\n",
    "    alphavantage_link = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={0}&apikey=5HZEUI5AFJB06BUK&datatype=csv&outputsize={1}'.format(ticker, outsize)\n",
    "    stockframe = pd.read_csv(alphavantage_link, index_col = 0).sort_index()[['open', 'close']]\n",
    "    stockframe['daily_ret'] = np.log(stockframe['close']/stockframe['close'].shift(1))\n",
    "    stockframe['intra_ret'] = np.log(stockframe['close']/stockframe['open'])\n",
    "    stockframe['ovrnt_ret'] = np.log(stockframe['open']/stockframe['close'].shift(1))\n",
    "    stockframe['daily_vol'] = stockframe.daily_ret.rolling(window=rolling_window,center=False).std()\n",
    "    stockframe['intra_vol'] = stockframe.intra_ret.rolling(window=rolling_window,center=False).std()\n",
    "    stockframe['ovrnt_vol'] = stockframe.ovrnt_ret.rolling(window=rolling_window,center=False).std()\n",
    "    stockframe['daily_ann'] = stockframe.daily_vol*np.sqrt(252)\n",
    "    stockframe['intra_ann'] = stockframe.intra_vol*np.sqrt((24/6.5)*252)\n",
    "    stockframe['ovrnt_ann'] = stockframe.ovrnt_vol*np.sqrt((24/17.5)*252)\n",
    "    stockframe['oc_diff'] = stockframe.close - stockframe.open\n",
    "    stockframe['daily_dollar_vol'] = stockframe.daily_vol*stockframe.close.shift(1)\n",
    "    stockframe['daily_dollar_std'] = np.abs(stockframe.oc_diff/stockframe.daily_dollar_vol)\n",
    "\n",
    "    return stockframe.tail(day_number)\n",
    "\n",
    "# Function for building a dataframe of volatilities\n",
    "# Daily, Intraday, Overnight\n",
    "def current_volatility(ticker_list, roll = 20):\n",
    "    \n",
    "    rows = []\n",
    "    failed_tickers = []\n",
    "    \n",
    "    def failed_check(failed_lst,rows):\n",
    "        if len(failed_lst) == 0:\n",
    "            return failed_lst, rows\n",
    "        else:\n",
    "            new_lst = []\n",
    "            new_rows = rows\n",
    "            for tick in failed_lst:\n",
    "                try: \n",
    "                    curr_vol = historical_data(tick, outsize = 'compact').tail(1)[['daily_ann','intra_ann','ovrnt_ann','close',\n",
    "                                                                                   'daily_dollar_vol']]\n",
    "                    curr_vol.index.name = 'Tickers'\n",
    "                    curr_vol.index = [tick]\n",
    "                    new_rows.append(curr_vol)\n",
    "                except:\n",
    "                    new_lst.append(tick)\n",
    "            return failed_check(new_lst, rows)\n",
    "\n",
    "    for tick in ticker_list:\n",
    "        try: \n",
    "            curr_vol = historical_data(tick, outsize = 'compact').tail(1)[['daily_ann','intra_ann','ovrnt_ann','close',\n",
    "                                                                           'daily_dollar_vol']]\n",
    "            curr_vol.index.name = 'Tickers'\n",
    "            curr_vol.index = [tick]\n",
    "            rows.append(curr_vol)\n",
    "        except:\n",
    "            failed_tickers.append(tick)\n",
    "            \n",
    "    failed_lst, rows = failed_check(failed_tickers, rows)\n",
    "        \n",
    "    return pd.concat(rows, axis = 0)\n",
    "\n",
    "# Function for pulling S&P500 data and calculating volatilities\n",
    "def sp500_filter():\n",
    "    sp500 = pull_sp500_list()\n",
    "    sp500_vols = current_volatility(sp500.index.tolist())\n",
    "    df = pd.concat([sp500_vols, sp500], axis = 1).dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_raw_data(ticker):\n",
    "    tape = Options(ticker, 'yahoo')\n",
    "    data = tape.get_all_data()\n",
    "    return data\n",
    "\n",
    "# Function for pulling options for a given ticker\n",
    "def option_filter(ticker, moneyness_thresh, dte_thresh):\n",
    "    fwd_date = dt.datetime.today() + dt.timedelta(days = dte_thresh)\n",
    "    tape = Options(ticker, 'yahoo')\n",
    "    data = tape.get_options_data(month = fwd_date.month, year = fwd_date.year).reset_index()\n",
    "    data['Moneyness'] = np.abs(data['Strike'] - data['Underlying_Price'])/data['Underlying_Price']\n",
    "    \n",
    "    data['DTE'] = (data['Expiry'] - dt.datetime.today()).dt.days\n",
    "    data = data[['Strike', 'DTE', 'Type', 'IV', 'Vol','Open_Int', 'Moneyness', 'Root', 'Underlying_Price',\n",
    "                 'Last','Bid','Ask']]\n",
    "    data['Mid'] = data['Ask'] - data['Bid']\n",
    "\n",
    "    filtered_data = data[(data['Moneyness'] <= moneyness_thresh) &\n",
    "                         (data['DTE'] <= dte_thresh)].reset_index()[data.columns]\n",
    "    put_ivs = filtered_data[filtered_data.Type == 'put'].pivot(index='Strike', columns='DTE', \n",
    "                                                               values='IV').dropna()\n",
    "    call_ivs = filtered_data[filtered_data.Type == 'put'].pivot(index='Strike', columns='DTE', \n",
    "                                                                values='IV').dropna()\n",
    "    hv_data = current_volatility([ticker])\n",
    "\n",
    "    put_ivs['Close'] = hv_data['close'][0]\n",
    "    call_ivs['Close'] = hv_data['close'][0]\n",
    "    put_ivs['Daily HV'] = hv_data['daily_ann'][0]\n",
    "    call_ivs['Daily HV'] = hv_data['daily_ann'][0]\n",
    "    put_ivs['Intra HV'] = hv_data['intra_ann'][0]\n",
    "    call_ivs['Intra HV'] = hv_data['intra_ann'][0]\n",
    "    put_ivs['Overnight HV'] = hv_data['ovrnt_ann'][0]\n",
    "    call_ivs['Overnight HV'] = hv_data['ovrnt_ann'][0]\n",
    "    put_ivs['Daily Dollar Vol'] = hv_data['daily_dollar_vol'][0]\n",
    "    call_ivs['Daily Dollar Vol'] = hv_data['daily_dollar_vol'][0]\n",
    "    \n",
    "    put_ivs['Moneyness'] = np.abs(put_ivs.index - put_ivs['Close'])/put_ivs['Close']\n",
    "    call_ivs['Moneyness'] = np.abs(call_ivs.index - call_ivs['Close'])/call_ivs['Close']\n",
    "\n",
    "    call_ivs.index.name = ticker + ' Call Strike'\n",
    "    put_ivs.index.name = ticker + ' Put Strike'\n",
    "    return call_ivs, put_ivs\n",
    "\n",
    "def phase1_options_filter(ticker_lst, hv_day_roll, atm_distance, dte_thresh, iv_hv_thresh):\n",
    "    \n",
    "    pulled_options = []\n",
    "    calls = {}\n",
    "    puts = {}\n",
    "\n",
    "    moneyness_thresh = atm_distance\n",
    "\n",
    "    for tick in ticker_lst:\n",
    "        try:\n",
    "            call, put = option_filter(tick, moneyness_thresh, dte_thresh)\n",
    "            \n",
    "            call_check = call.sort_values('Moneyness').head(1)\n",
    "            # Checking IV vs HV of the options chain out more than 2 weeks\n",
    "            iv_chain_to_check = list(filter(lambda x: x >= hv_day_roll, \n",
    "                                            list(filter(lambda x: type(x) == int,call_check.columns.tolist()))))[0]\n",
    "            \n",
    "            average_difference_iv_hv = abs(call_check[iv_chain_to_check] - call_check['Intra HV']).mean()\n",
    "\n",
    "            if average_difference_iv_hv >= iv_hv_thresh:\n",
    "                calls[tick] = call\n",
    "                puts[tick] = put\n",
    "                pulled_options.append(tick)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return pulled_options, calls, puts\n",
    "\n",
    "def greek_calc(ticker, dte_ub, dte_lb, prem_price_use = 'Mid', delta_filter = 0.2, expiry_set = 0):\n",
    "    options_chain = get_raw_data(ticker).reset_index()\n",
    "    options_chain = options_chain[['Strike','Expiry','Type','Last','Bid','Ask','Vol','Open_Int','IV','Underlying_Price']]\n",
    "    df = options_chain\n",
    "    df['DTE'] = (df['Expiry'] - dt.datetime.today()).dt.days\n",
    "    df['Mid'] = (df['Ask'] + df['Bid'])/2\n",
    "    df = df[(df['DTE'] <= dte_ub) & (df['DTE'] >= dte_lb)]\n",
    "    df = df.reset_index()[df.columns]\n",
    "    \n",
    "    year = 365\n",
    "    premiums = df[prem_price_use].values # 'Last' or 'Mid'\n",
    "    strikes = df['Strike'].values\n",
    "    time_to_expirations = df['DTE'].values\n",
    "    ivs = df['IV'].values\n",
    "    underlying = df['Underlying_Price'].values[0]\n",
    "    types = df['Type'].values\n",
    "\n",
    "    # Make sure nothing thows up\n",
    "    assert len(premiums) == len(strikes)\n",
    "    assert len(strikes) == len(time_to_expirations)\n",
    "\n",
    "    sigmas = []\n",
    "    deltas = []\n",
    "    gammas = []\n",
    "    thetas = []\n",
    "    vegas = []\n",
    "    prices = []\n",
    "    for premium, strike, time_to_expiration, flag in zip(premiums, strikes, time_to_expirations, types):\n",
    "\n",
    "        # Constants\n",
    "        P = premium\n",
    "        S = underlying\n",
    "        K = strike\n",
    "        t = time_to_expiration/float(year)\n",
    "        r = 0.005 / 100\n",
    "        q = 0 / 100\n",
    "        try:\n",
    "            sigma = implied_volatility(P, S, K, t, r, q, flag[0])\n",
    "            sigmas.append(sigma)\n",
    "        except:\n",
    "            sigma = 0.0\n",
    "            sigmas.append(sigma)\n",
    "\n",
    "        try:\n",
    "            delta = py_vollib.black_scholes_merton.greeks.analytical.delta(flag[0], S, K, t, r, sigma, q)\n",
    "            deltas.append(delta)\n",
    "        except:\n",
    "            delta = 0.0\n",
    "            deltas.append(delta)\n",
    "\n",
    "        try:\n",
    "            gamma = py_vollib.black_scholes_merton.greeks.analytical.gamma(flag[0], S, K, t, r, sigma, q)\n",
    "            gammas.append(gamma)\n",
    "        except:\n",
    "            gamma = 0.0\n",
    "            gammas.append(gamma)\n",
    "\n",
    "        try:\n",
    "            theta = py_vollib.black_scholes_merton.greeks.analytical.theta(flag[0], S, K, t, r, sigma, q)\n",
    "            thetas.append(theta)\n",
    "        except:\n",
    "            theta = 0.0\n",
    "            thetas.append(theta)\n",
    "\n",
    "        try:\n",
    "            vega = py_vollib.black_scholes_merton.greeks.analytical.vega(flag[0], S, K, t, r, sigma, q)\n",
    "            vegas.append(vega)\n",
    "        except:\n",
    "            vega = 0.0\n",
    "            vegas.append(vega)\n",
    "\n",
    "    ivs = np.array(sigmas)\n",
    "    df['Calc IV'] = ivs\n",
    "    df['Delta'] = deltas\n",
    "    df['Gamma'] = gammas\n",
    "    df['Theta'] = thetas\n",
    "    df['Vega'] = vegas\n",
    "    df = df.dropna()\n",
    "\n",
    "    expiry_filter = df.sort_values('DTE')['DTE'].drop_duplicates().values[min(expiry_set, \n",
    "                                                                              len(df.sort_values('DTE')['DTE'].drop_duplicates()))]\n",
    "\n",
    "    calls = df[(abs(df['Delta']) >= delta_filter) & \n",
    "               (df['Type'] == 'call') & \n",
    "               (df['DTE'] == expiry_filter)].reset_index()[df.columns]\n",
    "    puts = df[(abs(df['Delta']) >= delta_filter) & \n",
    "              (df['Type'] == 'put') & \n",
    "              (df['DTE'] == expiry_filter)].reset_index()[df.columns]\n",
    "    \n",
    "    return calls, puts\n",
    "\n",
    "def price_sim(options_df, price_change, vol_change, days_change, iv_tag = 'Calc IV', output = 'All'):\n",
    "    '''\n",
    "    output types can be: All, Price, Delta, Gamma, Vega, Theta\n",
    "    '''\n",
    "    year = 365\n",
    "    strikes = options_df['Strike'].values\n",
    "    time_to_expirations = options_df['DTE'].values\n",
    "    ivs = options_df[iv_tag].values\n",
    "    underlying = options_df['Underlying_Price'].values[0]\n",
    "    types = options_df['Type'].values\n",
    "\n",
    "    # Tweaking changes\n",
    "    prices = []\n",
    "    deltas = []\n",
    "    gammas = []\n",
    "    thetas = []\n",
    "    vegas = []\n",
    "    for sigma, strike, time_to_expiration, flag in zip(ivs, strikes, time_to_expirations, types):\n",
    "\n",
    "        # Constants\n",
    "        S = underlying*(1 + price_change)\n",
    "        t = max(time_to_expiration - days_change, 0)/float(year)\n",
    "        sigma = sigma + vol_change\n",
    "        K = strike\n",
    "        r = 0.005 / 100\n",
    "        q = 0 / 100\n",
    "        \n",
    "        if (output == 'All') or (output == 'Price'):\n",
    "            if days_change == time_to_expiration:\n",
    "                if flag == 'call':\n",
    "                    price = max(S - K, 0.0)\n",
    "                else:\n",
    "                    price = max(K - S, 0.0)\n",
    "                prices.append(price)\n",
    "            else:\n",
    "                try:\n",
    "                    price = py_vollib.black_scholes_merton.black_scholes_merton(flag[0], S, K, t, r, sigma, q)\n",
    "                    prices.append(price)\n",
    "                except:\n",
    "                    price = 0.0\n",
    "                    prices.append(price)\n",
    "                    \n",
    "        if (output == 'All') or (output == 'Delta'):\n",
    "            try:\n",
    "                delta = py_vollib.black_scholes_merton.greeks.analytical.delta(flag[0], S, K, t, r, sigma, q)\n",
    "                deltas.append(delta)\n",
    "            except:\n",
    "                delta = 0.0\n",
    "                deltas.append(delta)\n",
    "        \n",
    "        if (output == 'All') or (output == 'Gamma'):\n",
    "            try:\n",
    "                gamma = py_vollib.black_scholes_merton.greeks.analytical.gamma(flag[0], S, K, t, r, sigma, q)\n",
    "                gammas.append(gamma)\n",
    "            except:\n",
    "                gamma = 0.0\n",
    "                gammas.append(gamma)\n",
    "            \n",
    "        if (output == 'All') or (output == 'Theta'):\n",
    "            try:\n",
    "                theta = py_vollib.black_scholes_merton.greeks.analytical.theta(flag[0], S, K, t, r, sigma, q)\n",
    "                thetas.append(theta)\n",
    "            except:\n",
    "                theta = 0.0\n",
    "                thetas.append(theta)\n",
    "        \n",
    "        if (output == 'All') or (output == 'Vega'):\n",
    "            try:\n",
    "                vega = py_vollib.black_scholes_merton.greeks.analytical.vega(flag[0], S, K, t, r, sigma, q)\n",
    "                vegas.append(vega)\n",
    "            except:\n",
    "                vega = 0.0\n",
    "                vegas.append(vega)\n",
    "            \n",
    "    df = options_df[['Strike','Expiry','DTE','Type','Last','Bid','Ask','Mid','Underlying_Price']]\n",
    "    if (output == 'All') or (output == 'Price'):\n",
    "        df['Simulated Price'] = prices\n",
    "        df['Price Change'] = df['Simulated Price']/df['Mid'] - 1\n",
    "    if (output == 'All') or (output == 'Delta'):\n",
    "        df['Delta'] = deltas\n",
    "    if (output == 'All') or (output == 'Gamma'):\n",
    "        df['Gamma'] = gammas\n",
    "    if (output == 'All') or (output == 'Theta'):\n",
    "        df['Theta'] = thetas\n",
    "    if (output == 'All') or (output == 'Vega'):\n",
    "        df['Vega'] = vegas\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def position_sim(position_df, holdings, price_change, vol_change, dte_change, iv_tag = 'Calc IV', output = 'All'):\n",
    "    position = position_df\n",
    "    position['Cost'] = position['Mid']\n",
    "    position['Pos'] = holdings\n",
    "    position_dict = {}\n",
    "    position_dict['Total Cost'] = sum(position['Cost']*position['Pos'])\n",
    "    position_dict['Original Delta'] = sum(position['Delta']*position['Pos'])\n",
    "    position_dict['Original Gamma'] = sum(position['Gamma']*position['Pos'])\n",
    "    position_dict['Original Theta'] = sum(position['Theta']*position['Pos'])\n",
    "    position_dict['Original Vega'] = sum(position['Vega']*position['Pos'])\n",
    "    \n",
    "    if (output == 'PnL') or (output == 'Percent Return'):\n",
    "        simulation = price_sim(position, price_change, vol_change, dte_change, iv_tag, 'Price')\n",
    "    else:\n",
    "        simulation = price_sim(position, price_change, vol_change, dte_change, iv_tag, output)\n",
    "    \n",
    "    if (output == 'All') or (output == 'PnL') or (output == 'Percent Return'):\n",
    "        position_dict['Simulated Price'] = sum(simulation['Simulated Price']*position['Pos'])\n",
    "        position_dict['PnL'] = sum(simulation['Simulated Price']*position['Pos']) - position_dict['Total Cost']\n",
    "        if position_dict['Total Cost'] > 0:\n",
    "            position_dict['Percent Return'] = position_dict['PnL']/position_dict['Total Cost']\n",
    "        else:\n",
    "            position_dict['Percent Return'] = -position_dict['PnL']/position_dict['Total Cost']\n",
    "            \n",
    "    if (output == 'All') or (output == 'Delta'):\n",
    "        position_dict['Simulated Delta'] = sum(simulation['Delta']*position['Pos'])\n",
    "        \n",
    "    if (output == 'All') or (output == 'Gamma'):\n",
    "        position_dict['Simulated Gamma'] = sum(simulation['Gamma']*position['Pos'])\n",
    "        \n",
    "    if (output == 'All') or (output == 'Theta'):\n",
    "        position_dict['Simulated Theta'] = sum(simulation['Theta']*position['Pos'])\n",
    "        \n",
    "    if (output == 'All') or (output == 'Vega'):\n",
    "        position_dict['Simulated Vega'] = sum(simulation['Vega']*position['Pos'])\n",
    "    \n",
    "    outframe = pd.DataFrame(position_dict, index = [vol_change])\n",
    "    return outframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 38761.15459251404 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# active_stock_fundas = get_fundas(active_stocks[active_stocks['Last'] >= 30].index.tolist())\n",
    "# active_stock_fundas = active_stock_fundas[active_stock_fundas['Market Cap (B)'] >= 5]\n",
    "# tick_lst = july16_earnings['Tickers'].tolist() #\n",
    "tick_lst = active_stocks[active_stocks['Last'] >= 30].index.tolist()\n",
    "etfs_lst = active_etfs[active_etfs['Last'] >= 50].index.tolist()\n",
    "days_since_earnings_threshold = 30\n",
    "mkt_cap_thresh = 5\n",
    "moneyness_thresh = 0.05\n",
    "hv_roll = 22\n",
    "dte_thresh = 30\n",
    "sort_on = 'intra_ann'\n",
    "max_options_num = 10 # Maximum number of names to look up\n",
    "iv_hv_thres = 0.9\n",
    "\n",
    "vols = current_volatility(tick_lst, roll = 22)\n",
    "etfs = current_volatility(etfs_lst, roll = 22).sort_values([sort_on], ascending = False).dropna()\n",
    "vols = vols.sort_values([sort_on], ascending = False).dropna()\n",
    "fundas = get_fundas(vols.index.tolist())\n",
    "tickers = pd.concat([vols,fundas],axis = 1)\n",
    "# tickers = tickers[(tickers['Days Since Last Earnings'] >= days_since_earnings_threshold) &\n",
    "#                   (tickers['Market Cap (B)'] <= 1)].sort_values([sort_on], ascending = False)\n",
    "\n",
    "# etf_ticks = etfs.sort_values([sort_on], ascending = False)\n",
    "\n",
    "# pulled_options, pulled_calls, pulled_puts = phase1_options_filter(tickers.index.tolist()[:max_options_num], \n",
    "#                                                                   hv_roll, moneyness_thresh, dte_thresh,\n",
    "#                                                                   iv_hv_thres)\n",
    "\n",
    "# pulled_etfs, pulled_etfcalls, pulled_etfputs = phase1_options_filter(etf_ticks.index.tolist()[:max_options_num], \n",
    "#                                                                      hv_roll, moneyness_thresh, dte_thresh,\n",
    "#                                                                      iv_hv_thres)\n",
    "\n",
    "# filtered_single_names = (tickers.transpose()[pulled_options]).transpose()\n",
    "# filtered_single_names = (tickers.transpose()[pulled_options]).transpose()\n",
    "# filtered_single_names['IV'] = np.nan\n",
    "# for stock in pulled_options:\n",
    "#     filtered_single_names.loc[stock,'IV'] = pulled_puts[stock].sort_values(['Moneyness']).head(1).iloc[:, 0:-6].iloc[:,-1].iloc[0]\n",
    "    \n",
    "# filtered_etfs = (etf_ticks.transpose()[pulled_etfs]).transpose()\n",
    "# filtered_etfs = (etf_ticks.transpose()[pulled_etfs]).transpose()\n",
    "# filtered_etfs['IV'] = np.nan\n",
    "# for etf in pulled_etfs:\n",
    "#     filtered_etfs.loc[etf,'IV'] = pulled_etfputs[etf].sort_values(['Moneyness']).head(1).iloc[:, 0:-6].iloc[:,-1].iloc[0]\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily_ann</th>\n",
       "      <th>intra_ann</th>\n",
       "      <th>ovrnt_ann</th>\n",
       "      <th>close</th>\n",
       "      <th>daily_dollar_vol</th>\n",
       "      <th>1y Target Est</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Days Since Last Earnings</th>\n",
       "      <th>Div</th>\n",
       "      <th>EPS (TTM)</th>\n",
       "      <th>Earnings Date</th>\n",
       "      <th>Ex-Dividend Date</th>\n",
       "      <th>Market Cap (B)</th>\n",
       "      <th>PE Ratio (TTM)</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAOI</th>\n",
       "      <td>0.786891</td>\n",
       "      <td>1.326712</td>\n",
       "      <td>0.250431</td>\n",
       "      <td>42.15</td>\n",
       "      <td>2.086875</td>\n",
       "      <td>37.29</td>\n",
       "      <td>1.35</td>\n",
       "      <td>119.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.79</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.825255</td>\n",
       "      <td>15.10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCS</th>\n",
       "      <td>0.449467</td>\n",
       "      <td>0.850250</td>\n",
       "      <td>0.087507</td>\n",
       "      <td>31.90</td>\n",
       "      <td>0.920196</td>\n",
       "      <td>39.90</td>\n",
       "      <td>0.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.30</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.950113</td>\n",
       "      <td>13.87</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DQ</th>\n",
       "      <td>0.980583</td>\n",
       "      <td>1.790575</td>\n",
       "      <td>0.286779</td>\n",
       "      <td>34.92</td>\n",
       "      <td>2.185455</td>\n",
       "      <td>49.37</td>\n",
       "      <td>0.94</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.02</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.449204</td>\n",
       "      <td>3.87</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GDEN</th>\n",
       "      <td>0.279597</td>\n",
       "      <td>0.547427</td>\n",
       "      <td>0.102944</td>\n",
       "      <td>29.58</td>\n",
       "      <td>0.544241</td>\n",
       "      <td>38.50</td>\n",
       "      <td>1.02</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.810125</td>\n",
       "      <td>954.19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIIQ</th>\n",
       "      <td>0.397480</td>\n",
       "      <td>0.731926</td>\n",
       "      <td>0.098512</td>\n",
       "      <td>34.15</td>\n",
       "      <td>0.835047</td>\n",
       "      <td>48.38</td>\n",
       "      <td>0.85</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.29</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.603618</td>\n",
       "      <td>26.45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PETS</th>\n",
       "      <td>0.290833</td>\n",
       "      <td>0.528635</td>\n",
       "      <td>0.058215</td>\n",
       "      <td>45.53</td>\n",
       "      <td>0.819854</td>\n",
       "      <td>46.75</td>\n",
       "      <td>0.82</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.70</td>\n",
       "      <td></td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>0.929158</td>\n",
       "      <td>26.78</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCHN</th>\n",
       "      <td>0.420059</td>\n",
       "      <td>0.576969</td>\n",
       "      <td>0.209487</td>\n",
       "      <td>36.15</td>\n",
       "      <td>0.919529</td>\n",
       "      <td>38.33</td>\n",
       "      <td>1.36</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.26</td>\n",
       "      <td></td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>0.949950</td>\n",
       "      <td>15.99</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      daily_ann  intra_ann  ovrnt_ann  close  daily_dollar_vol 1y Target Est  \\\n",
       "AAOI   0.786891   1.326712   0.250431  42.15          2.086875         37.29   \n",
       "CCS    0.449467   0.850250   0.087507  31.90          0.920196         39.90   \n",
       "DQ     0.980583   1.790575   0.286779  34.92          2.185455         49.37   \n",
       "GDEN   0.279597   0.547427   0.102944  29.58          0.544241         38.50   \n",
       "HIIQ   0.397480   0.731926   0.098512  34.15          0.835047         48.38   \n",
       "PETS   0.290833   0.528635   0.058215  45.53          0.819854         46.75   \n",
       "SCHN   0.420059   0.576969   0.209487  36.15          0.919529         38.33   \n",
       "\n",
       "      Beta  Days Since Last Earnings   Div EPS (TTM) Earnings Date  \\\n",
       "AAOI  1.35                     119.0   NaN      2.79                 \n",
       "CCS   0.75                      56.0   NaN      2.30                 \n",
       "DQ    0.94                      43.0   NaN      9.02                 \n",
       "GDEN  1.02                      97.0   NaN      0.03           N/A   \n",
       "HIIQ  0.85                      49.0   NaN      1.29                 \n",
       "PETS  0.82                      45.0  1.00      1.70                 \n",
       "SCHN  1.36                      76.0  0.75      2.26                 \n",
       "\n",
       "     Ex-Dividend Date  Market Cap (B) PE Ratio (TTM)  Yield  \n",
       "AAOI              N/A        0.825255          15.10    NaN  \n",
       "CCS               N/A        0.950113          13.87    NaN  \n",
       "DQ                N/A        0.449204           3.87    NaN  \n",
       "GDEN       2016-06-28        0.810125         954.19    NaN  \n",
       "HIIQ              N/A        0.603618          26.45    NaN  \n",
       "PETS       2018-02-02        0.929158          26.78   2.87  \n",
       "SCHN       2018-02-09        0.949950          15.99   2.36  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tickers.to_csv('filtered_names.csv')\n",
    "tickers[tickers['Market Cap (B)'] <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "call_ivs, put_ivs = option_filter('BABA', moneyness_thresh, dte_thresh)\n",
    "\n",
    "test = call_ivs.iloc[:, 0:-6].iloc[:,-1]\n",
    "test.columns = ['IV']\n",
    "test['Strikes'] = test.index\n",
    "r_sqrd = result.rsquared\n",
    "slope = result.params.Strikes\n",
    "\n",
    "# vol2 = vols\n",
    "# vol2['hv_ratio'] = vol2['intra_ann']/vol2['daily_ann']\n",
    "# vol2 = vol2.sort_values(['hv_ratio', 'intra_ann'], ascending = False)\n",
    "# vol2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
