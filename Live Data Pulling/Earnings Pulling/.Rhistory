glm.pred = rep("No", length(glm.probs))
glm.pred[glm.probs > .5] = "Yes"
# iv.
table(glm.pred, test.Y)
(142+19)/(5854+142+19+66
)
mean(glm.pred != test.Y)
set.seed(1)
x = rnorm(100)
epsilon = rnorm(100)
b0 = 1
b1 = 2
b2 = 3
b3 = 4
y = b0 + b1*x + b2*x^2 + b3*x^3 + epsilon
plot(x, y)
library(leaps)
regfit.full = regsubsets(y~., data = data.frame(poly(x, 10), y), nvmax = 10)
install.packages(leaps)
install.packages('leaps')
library(leaps)
reg.summary = summary(regfit.full)
regfit.full = regsubsets(y~., data = data.frame(poly(x, 10), y), nvmax = 10)
reg.summary = summary(regfit.full)
par(mfrow = c(2,2))
plot(reg.summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
points(which.min(reg.summary$rss), min(reg.summary$rss), col = "red", cex = 2, pch = 20)
plot(reg.summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
plot(reg.summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
points(which.min(reg.summary$rss), min(reg.summary$rss), col = "red", cex = 2, pch = 20)
install.packages('glmnet')
library(glmnet)
library(glmnet)
xmat = model.matrix(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full)[, -1]
data.full = data.frame(y = y, x = x)
regfit.full = regsubsets(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full, nvmax = 10)
reg.summary = summary(regfit.full)
xmat = model.matrix(y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) + I(x^7) + I(x^8) + I(x^9) + I(x^10), data = data.full)[, -1]
cv.lasso = cv.glmnet(xmat, y, alpha = 1)
plot(cv.lasso)
library(ISLR)
attach(Smarket)
summary(Smarket)
train = (Year < 2005)
?hatvalues
??hatvalues
# Logistic Regression
library(lubridate)
library(dplyr)
library(nnet)
library(kable)
setwd("C:/Users/fchen/Desktop/Python Trading/SPX-Put-Selling/Live Data Pulling/Earnings Pulling")
install.packages('kable')
library(purrr)
library(magrittr)
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
View(dataset)
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-03-31'))
train = train[,columns]
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-03-31'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-03-31'))
test = test[,columns]
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
View(dataset)
colnames(dataset)
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
View(dataset)
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
valid = dataset %>%
filter(quarter >= as.Date('2018-05-31'))
View(valid)
View(valid)
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
View(best_set)
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
View(dataset)
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
View(dataset)
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
View(dataset)
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
View(test_y_actual)
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
train = train[,columns]
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%Y-%m-%d")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
# Importing the dataset
dataset = read.csv('earnHist_v3.csv')
dataset$quarter = as.Date(dataset$quarter, "%m/%d/%Y")
columns = c("X1Year","X1month","industry","current_ratio",'total_debt_equity_ratio',
'day_sales_outstanding','gross_margin','operating_margin',
'interest_coverage_ratio','net_profit_margin','roe','changeToLiabilities',
'changeToNetincome','changeToOperatingActivities','return_factor')
# Splitting the dataset into the Training set and Test set
train = dataset %>%
filter(quarter < as.Date('2018-04-30'))
train = train[,columns]
test = dataset %>%
filter(quarter >= as.Date('2018-04-30'))
test = test[,columns]
test_y_actual = data.frame(test$return_factor)
for(level in unique(test_y_actual$test.return_factor)){
test_y_actual[level] <- ifelse(test_y_actual$test.return_factor == level, 1, 0)
}
# define model grid for best subset regression
# defines which predictors are on/off; all combinations presented
model.grid = function(n){
n.list = rep(list(0:1), n)
expand.grid(n.list)
}
best_set = length(columns) %>%
model.grid %>%
apply(1, function(x) which(x > 0, arr.ind = TRUE)) %>%
map(function(x) columns[x]) %>%
.[2:dim(model.grid(length(columns)))[1]]
ests = list()
i = 1
for (set in best_set) {
curr_reg = multinom(paste0('return_factor', " ~ ", paste(set, collapse = "+")),
data = train)
# Predicting the Test set results
prob_pred = predict(curr_reg, test, "probs")
y_pred = ifelse(prob_pred > 0.7, 1, 0)
# Making the Confusion Matrix
cm = table(unlist(test_y_actual[,c('down','flat','up')]), unlist(y_pred))
result = tryCatch(
{cm[2,2]},
error = function(cond) {
return(0)
}
)
ests[[i]] = result
i = i + 1
}
ests
which(ests == max(ests))
ests_array = unlist(ests)
which(ests_array == max(ests_array))
which(ests_array == max(ests_array))[0]
ests_array[14428]
ests_array[14556]
best_set[14556]
best_set[which(ests_array == max(ests_array))]
save.image("C:/Users/fchen/Desktop/Python Trading/SPX-Put-Selling/Live Data Pulling/Earnings Pulling/earnings_env.RData")
